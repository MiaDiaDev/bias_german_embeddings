{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train FastText embeddings using gensim (Source: https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus & Preprocess raw text (Remove punctuation and numbers) (5600-6000 sec. = ca. 1.5h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "new_corpus = []\n",
    "#i=1\n",
    "with open('raw_data/deu_news_2020_1M-sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        doc = nlp(line)\n",
    "        new_line = [token.lower_ for token in doc if token.is_alpha]\n",
    "        for j in range(10):\n",
    "            new_line.append('$')\n",
    "        new_corpus.append(' '.join(new_line))\n",
    "        #i+=1\n",
    "        #if i>200:\n",
    "            #break \n",
    "    f.close()\n",
    "\n",
    "with open('clean_data/deu_news_2020_clean.txt', 'w', encoding='utf-8') as f_out:\n",
    "    for line in new_corpus:\n",
    "        f_out.write(line)\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model (window=5 10 min., 3 -> 6 min., 10 -> 12 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1995 = FastText(sg=1, vector_size=300, window=10)\n",
    "corpus_file_1995 = 'clean_data/deu_news_1995_clean.txt'\n",
    "\n",
    "# build the vocabulary\n",
    "model_1995.build_vocab(corpus_file=corpus_file_1995)\n",
    "\n",
    "# train the model\n",
    "model_1995.train(\n",
    "    corpus_file=corpus_file_1995, epochs=model_1995.epochs,\n",
    "    total_examples=model_1995.corpus_count, total_words=model_1995.corpus_total_words,\n",
    ")\n",
    "\n",
    "print(model_1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vector lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = model_1995.wv\n",
    "print(wv_1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print example word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995['nacht'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print example vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.similarity(\"nacht\", \"dunkelheit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load other corpus & build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2010 = 'clean_data/deu_news_2010_clean.txt'\n",
    "model_2010 = FastText(sg=1, vector_size=300)\n",
    "\n",
    "corpus_file_2020 = 'clean_data/deu_news_2020_clean.txt'\n",
    "model_2020 = FastText(sg=1, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabularies\n",
    "model_2010.build_vocab(corpus_file=corpus_file_2010)\n",
    "model_2020.build_vocab(corpus_file=corpus_file_2020)\n",
    "\n",
    "# train models\n",
    "model_2010.train(\n",
    "    corpus_file=corpus_file_2010, epochs=model_2010.epochs,\n",
    "    total_examples=model_2010.corpus_count, total_words=model_2010.corpus_total_words,\n",
    ")\n",
    "model_2020.train(\n",
    "    corpus_file=corpus_file_2020, epochs=model_2020.epochs,\n",
    "    total_examples=model_2020.corpus_count, total_words=model_2020.corpus_total_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_2010 = model_2010.wv\n",
    "wv_2020 = model_2020.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save words & their embeddings (once training is complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wv_1995.save(\"trained_models/model_1995_training_3_wordvectors\")\n",
    "#wv_2010.save(\"trained_models/model_2010_wordvectors\")\n",
    "#wv_2020.save(\"trained_models/model_2020_wordvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models (2-6 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = KeyedVectors.load(\"trained_models/model_1995_training_3_wordvectors\", mmap='r')\n",
    "wv_2010 = KeyedVectors.load(\"trained_models/model_2010_training_3_wordvectors\", mmap='r')\n",
    "wv_2020 = KeyedVectors.load(\"trained_models/model_2020_training_3_wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some semantic similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_1995.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_1995.similarity(\"frau\", \"ärztin\"))\n",
    "print(wv_1995.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_1995.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_1995.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_2010.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_2010.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_2010.similarity(\"frau\", \"ärztin\"))\n",
    "print(wv_2010.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_2010.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_2010.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_2020.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_2020.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_2020.similarity(\"frau\", \"ärztin\"))\n",
    "print(wv_2020.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_2020.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_2020.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print words with most similar vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.most_similar(\"arzt\"))\n",
    "print(wv_2010.most_similar(\"arzt\"))\n",
    "print(wv_2020.most_similar(\"arzt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example analogy set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.most_similar(positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(wv_2010.most_similar(positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(wv_2020.most_similar(positive=['frau', 'arzt'], negative=['mann']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization with PCA (Source: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/) > 12 min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a 2d PCA model to the vectors\n",
    "X = wv_1995\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(wv_1995[:20])\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "display_pca_scatterplot(model, sample=300)\n",
    "\n",
    "# display_pca_scatterplot(model, ['frau', 'mann', 'arzt', 'ärztin'])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate general performance on semantic German analogy set, Source: https://devmount.github.io/GermanWordEmbeddings/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_1995.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_2010.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_2020.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim English question set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analogies_result = wv_2020.evaluate_word_analogies('questions/gensim questions-words.txt')\n",
    "#print(analogies_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Word Embedding Association Test (WEAT) by Chaloner & Maldonado (2019)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias categories:\n",
    "\n",
    "B1: career vs family\n",
    "B2: maths vs arts \n",
    "B3: science vs arts \n",
    "B4: intelligence vs appearance\n",
    "B5: strength vs weakness\n",
    "\n",
    "Both groups of target words per category are compared to the two attribute sets female and male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models and save word vectors with gensim 3.7.3 (10 min. per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_1995 = 'clean_data/deu_news_1995_clean.txt'\n",
    "model_1995 = FastText(sg=1, size=300)\n",
    "model_1995.build_vocab(corpus_file=corpus_file_1995)\n",
    "model_1995.train(\n",
    "    corpus_file=corpus_file_1995, epochs=model_1995.epochs,\n",
    "    total_examples=model_1995.corpus_count, total_words=model_1995.corpus_total_words,\n",
    ")\n",
    "wv_1995 = model_1995.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2010 = 'clean_data/deu_news_2010_clean.txt'\n",
    "model_2010 = FastText(sg=1, size=300)\n",
    "model_2010.build_vocab(corpus_file=corpus_file_2010)\n",
    "model_2010.train(\n",
    "    corpus_file=corpus_file_2010, epochs=model_2010.epochs,\n",
    "    total_examples=model_2010.corpus_count, total_words=model_2010.corpus_total_words,\n",
    ")\n",
    "wv_2010 = model_2010.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2020 = 'clean_data/deu_news_2020_clean.txt'\n",
    "model_2020 = FastText(sg=1, size=300)\n",
    "model_2020.build_vocab(corpus_file=corpus_file_2020)\n",
    "model_2020.train(\n",
    "    corpus_file=corpus_file_2020, epochs=model_2020.epochs,\n",
    "    total_examples=model_2020.corpus_count, total_words=model_2020.corpus_total_words,\n",
    ")\n",
    "wv_2020 = model_2020.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save old version keyed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995.save(\"gensim3.7_models/old_vectors_1995.kv\")\n",
    "wv_2010.save(\"gensim3.7_models/old_vectors_2010.kv\")\n",
    "wv_2020.save(\"gensim3.7_models/old_vectors_2020.kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load old version keyed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = KeyedVectors.load(\"gensim3.7_models/old_vectors_1995.kv\", mmap='r')\n",
    "wv_2010 = KeyedVectors.load(\"gensim3.7_models/old_vectors_2010.kv\", mmap='r')\n",
    "wv_2020 = KeyedVectors.load(\"gensim3.7_models/old_vectors_2020.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration with Responsibly (https://docs.responsibly.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.we.utils import most_similar, cosine_similarities_by_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute most similar words without restriction (words from sets may be repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(word_vectors, positive=['frau', 'arzt'], negative=['mann'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_occupation_list = ['arzt','ärztin','krankenschwester','krankenpfleger']\n",
    "print(cosine_similarities_by_words(word_vectors, 'frau', sample_occupation_list))\n",
    "print(cosine_similarities_by_words(word_vectors, 'mann', sample_occupation_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read translated wordlists by Chaloner & Maldonado to dict\n",
    "\"\"\"import os\n",
    "\n",
    "path = 'WEAT_german'\n",
    "#os.chdir(path)\n",
    "\n",
    "for file in os.listdir():\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        words = f.readlines()\n",
    "        new_words = [word.strip('\\n') for word in words]\n",
    "        #create dict for WEAT\n",
    "        weat_dict = {file.strip('.txt'), new_words}\n",
    "        f.close()\n",
    "\n",
    "print(file)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'wissenschaft',\n",
      " 'words': ['wissenschaft',\n",
      "           'technologie',\n",
      "           'physik',\n",
      "           'chemie',\n",
      "           'Einstein',\n",
      "           'NASA',\n",
      "           'experiment',\n",
      "           'astronomie']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('WEAT_german/wissenschaft.json', encoding='utf-8') as data:\n",
    "    wis_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "print(wis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'kunst',\n",
      " 'words': ['poesie',\n",
      "           'kunst',\n",
      "           'Shakespeare',\n",
      "           'tanz',\n",
      "           'literatur',\n",
      "           'roman',\n",
      "           'sinfonie',\n",
      "           'drama']}\n"
     ]
    }
   ],
   "source": [
    "with open('WEAT_german/kunst.json', encoding='utf-8') as data:\n",
    "    kunst_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "print(kunst_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'weiblich',\n",
      " 'words': ['weiblich',\n",
      "           'frau',\n",
      "           'mädchen',\n",
      "           'schwester',\n",
      "           'sie',\n",
      "           'ihr',\n",
      "           'ihrer',\n",
      "           'tochter',\n",
      "           'mutter',\n",
      "           'tante',\n",
      "           'großmutter']}\n"
     ]
    }
   ],
   "source": [
    "with open('WEAT_german/weiblich.json', encoding='utf-8') as data:\n",
    "    w_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "print(w_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'männlich',\n",
      " 'words': ['männlich',\n",
      "           'mann',\n",
      "           'junge',\n",
      "           'bruder',\n",
      "           'er',\n",
      "           'ihm',\n",
      "           'sein',\n",
      "           'sohn',\n",
      "           'vater',\n",
      "           'onkel',\n",
      "           'großvater']}\n"
     ]
    }
   ],
   "source": [
    "with open('WEAT_german/maennlich.json', encoding='utf-8') as data:\n",
    "    m_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "print(m_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B3: science vs arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'wissenschaft vs. kunst',\n",
       " 'Attrib. words': 'weiblich vs. männlich',\n",
       " 's': 0.04902267828583717,\n",
       " 'd': 0.17989883,\n",
       " 'p': 0.3714840714840715,\n",
       " 'Nt': '8x2',\n",
       " 'Na': '11x2'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from responsibly.we.weat import calc_single_weat\n",
    "\n",
    "calc_single_weat(model=wv_1995, \n",
    "                    first_target=wis_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'wissenschaft vs. kunst',\n",
       " 'Attrib. words': 'weiblich vs. männlich',\n",
       " 's': -0.10826525837182999,\n",
       " 'd': -0.45867202,\n",
       " 'p': 0.8036519036519036,\n",
       " 'Nt': '8x2',\n",
       " 'Na': '11x2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_single_weat(model=wv_2010, \n",
    "                    first_target=wis_dict,  \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'wissenschaft vs. kunst',\n",
       " 'Attrib. words': 'weiblich vs. männlich',\n",
       " 's': -0.25144657120108604,\n",
       " 'd': -0.7853238,\n",
       " 'p': 0.933100233100233,\n",
       " 'Nt': '8x2',\n",
       " 'Na': '11x2'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_single_weat(model=wv_2020, \n",
    "                    first_target=wis_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gonen & Goldberg\n",
    "plot_most_biased_clustering(biased, debiased, seed='ends', n_extreme=500, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Test Bolukbasi measures?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1e59edebc369ad65c119260e2f960d0c0cce7d7d487e1def8281e3e9d8bc7df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
