{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train FastText embeddings using gensim</b> (Source: https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus & Preprocess raw text (Remove punctuation and numbers) (ca. 1.5h per corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "new_corpus = []\n",
    "#i=1\n",
    "with open('raw_data/deu_news_2020_1M-sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        doc = nlp(line)\n",
    "        new_line = [token.lower_ for token in doc if token.is_alpha]\n",
    "        for j in range(10):\n",
    "            new_line.append('$')\n",
    "        new_corpus.append(' '.join(new_line))\n",
    "        #i+=1\n",
    "        #if i>200:\n",
    "            #break \n",
    "    f.close()\n",
    "\n",
    "with open('clean_data/deu_news_2020_clean.txt', 'w', encoding='utf-8') as f_out:\n",
    "    for line in new_corpus:\n",
    "        f_out.write(line)\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model (window=5 10 min., 3 -> 6 min., 10 -> 12 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1995 = FastText(sg=1, vector_size=300, window=10)\n",
    "corpus_file_1995 = 'clean_data/deu_news_1995_clean.txt'\n",
    "\n",
    "# build the vocabulary\n",
    "model_1995.build_vocab(corpus_file=corpus_file_1995)\n",
    "\n",
    "# train the model\n",
    "model_1995.train(\n",
    "    corpus_file=corpus_file_1995, epochs=model_1995.epochs,\n",
    "    total_examples=model_1995.corpus_count, total_words=model_1995.corpus_total_words,\n",
    ")\n",
    "\n",
    "print(model_1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vector lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = model_1995.wv\n",
    "print(wv_1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load other corpus & build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2010 = 'clean_data/deu_news_2010_clean.txt'\n",
    "model_2010 = FastText(sg=1, vector_size=300)\n",
    "\n",
    "corpus_file_2020 = 'clean_data/deu_news_2020_clean.txt'\n",
    "model_2020 = FastText(sg=1, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabularies\n",
    "model_2010.build_vocab(corpus_file=corpus_file_2010)\n",
    "model_2020.build_vocab(corpus_file=corpus_file_2020)\n",
    "\n",
    "# train models\n",
    "model_2010.train(\n",
    "    corpus_file=corpus_file_2010, epochs=model_2010.epochs,\n",
    "    total_examples=model_2010.corpus_count, total_words=model_2010.corpus_total_words,\n",
    ")\n",
    "model_2020.train(\n",
    "    corpus_file=corpus_file_2020, epochs=model_2020.epochs,\n",
    "    total_examples=model_2020.corpus_count, total_words=model_2020.corpus_total_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_2010 = model_2010.wv\n",
    "wv_2020 = model_2020.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save words & their embeddings (once training is complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wv_1995.save(\"trained_models/model_1995_training_3_wordvectors\")\n",
    "#wv_2010.save(\"trained_models/model_2010_wordvectors\")\n",
    "#wv_2020.save(\"trained_models/model_2020_wordvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models (2-6 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = KeyedVectors.load(\"trained_models/model_1995_training_3_wordvectors\", mmap='r')\n",
    "wv_2010 = KeyedVectors.load(\"trained_models/model_2010_training_3_wordvectors\", mmap='r')\n",
    "wv_2020 = KeyedVectors.load(\"trained_models/model_2020_training_3_wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some semantic similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_1995.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_1995.similarity(\"frau\", \"ärztin\"))\n",
    "print(wv_1995.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_1995.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_1995.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_2010.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_2010.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_2010.similarity(\"frau\", \"ärztin\"))\n",
    "print(wv_2010.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_2010.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_2010.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_2020.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_2020.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_2020.similarity(\"frau\", \"ärztin\"))\n",
    "print(wv_2020.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_2020.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_2020.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print words with most similar vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.most_similar(\"arzt\"))\n",
    "print(wv_2010.most_similar(\"arzt\"))\n",
    "print(wv_2020.most_similar(\"arzt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example analogy set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.most_similar(positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(wv_2010.most_similar(positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(wv_2020.most_similar(positive=['frau', 'arzt'], negative=['mann']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization with PCA (Source: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/) > 12 min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a 2d PCA model to the vectors\n",
    "X = wv_1995\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(wv_1995[:20])\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "display_pca_scatterplot(model, sample=300)\n",
    "\n",
    "# display_pca_scatterplot(model, ['frau', 'mann', 'arzt', 'ärztin'])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate general performance on semantic German analogy set, Source: https://devmount.github.io/GermanWordEmbeddings/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_1995.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_2010.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_2020.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim English question set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analogies_result = wv_2020.evaluate_word_analogies('questions/gensim questions-words.txt')\n",
    "#print(analogies_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Word Embedding Association Test (WEAT) by Chaloner & Maldonado (2019)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias categories:\n",
    "\n",
    "B1: career vs family\n",
    "B2: maths vs arts \n",
    "B3: science vs arts \n",
    "B4: intelligence vs appearance\n",
    "B5: strength vs weakness\n",
    "\n",
    "Both groups of target words per category are compared to the two attribute sets female and male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models and save word vectors with gensim 4.0.1 (10 min. per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_1995 = 'clean_data/deu_news_1995_clean.txt'\n",
    "model_1995 = FastText(sg=1, size=300, window=10)\n",
    "model_1995.build_vocab(corpus_file=corpus_file_1995)\n",
    "model_1995.train(\n",
    "    corpus_file=corpus_file_1995, epochs=model_1995.epochs,\n",
    "    total_examples=model_1995.corpus_count, total_words=model_1995.corpus_total_words,\n",
    ")\n",
    "wv_1995 = model_1995.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2010 = 'clean_data/deu_news_2010_clean.txt'\n",
    "model_2010 = FastText(sg=1, size=300, window=10)\n",
    "model_2010.build_vocab(corpus_file=corpus_file_2010)\n",
    "model_2010.train(\n",
    "    corpus_file=corpus_file_2010, epochs=model_2010.epochs,\n",
    "    total_examples=model_2010.corpus_count, total_words=model_2010.corpus_total_words,\n",
    ")\n",
    "wv_2010 = model_2010.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2020 = 'clean_data/deu_news_2020_clean.txt'\n",
    "model_2020 = FastText(sg=1, size=300, window=10)\n",
    "model_2020.build_vocab(corpus_file=corpus_file_2020)\n",
    "model_2020.train(\n",
    "    corpus_file=corpus_file_2020, epochs=model_2020.epochs,\n",
    "    total_examples=model_2020.corpus_count, total_words=model_2020.corpus_total_words,\n",
    ")\n",
    "wv_2020 = model_2020.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save old version keyed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995.save(\"gensim4.0.1_ft_models/vectors_1995.kv\")\n",
    "wv_2010.save(\"gensim4.0.1_ft_models/vectors_2010.kv\")\n",
    "wv_2020.save(\"gensim4.0.1_ft_models/vectors_2020.kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load old version keyed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = KeyedVectors.load(\"gensim4.0.1_ft_models/vectors_1995.kv\", mmap='r')\n",
    "wv_2010 = KeyedVectors.load(\"gensim4.0.1_ft_models/vectors_2010.kv\", mmap='r')\n",
    "wv_2020 = KeyedVectors.load(\"gensim4.0.1_ft_models/vectors_2020.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration with Responsibly (https://docs.responsibly.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.we.utils import most_similar, cosine_similarities_by_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute most similar words without restriction (words from sets may be repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('arzt', 0.7294990356421993),\n",
      " ('patientin', 0.6411809819084028),\n",
      " ('ärztin', 0.6019659485813017),\n",
      " ('hausarzt', 0.5998664150539841),\n",
      " ('physiotherapeutin', 0.579768095891821),\n",
      " ('therapeutin', 0.5710132638183131),\n",
      " ('hautarzt', 0.5633543766755207),\n",
      " ('medizinerin', 0.561739535056716),\n",
      " ('arzthelferin', 0.5613126716369358),\n",
      " ('patient', 0.5597132866626509)]\n",
      "[('arzt', 0.7453792053776191),\n",
      " ('frauenarzt', 0.6158223903324075),\n",
      " ('hausarzt', 0.5977107747931595),\n",
      " ('patientin', 0.5826124837682605),\n",
      " ('zahnarzt', 0.5791214804080856),\n",
      " ('ärztin', 0.574488448786975),\n",
      " ('medizinerin', 0.5728439805654315),\n",
      " ('tierarzt', 0.562282196262649),\n",
      " ('frau', 0.5553649950714564),\n",
      " ('arztberuf', 0.5454157208356099)]\n",
      "[('arzt', 0.7787683393165297),\n",
      " ('ärztin', 0.6663402508733298),\n",
      " ('hausarzt', 0.6365236662554131),\n",
      " ('frauenarzt', 0.6265268355491721),\n",
      " ('hausärztin', 0.6176358832638997),\n",
      " ('zahnärztin', 0.6144357211383189),\n",
      " ('zahnarzt', 0.6106656290968133),\n",
      " ('amtsarzt', 0.6020358630467473),\n",
      " ('amtsärztin', 0.600272402110545),\n",
      " ('tierärztin', 0.5956269033677408)]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar(wv_1995, positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(most_similar(wv_2010, positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(most_similar(wv_2020, positive=['frau', 'arzt'], negative=['mann']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0.26169273, 0.44548863, 0.46253282, 0.335657  ], dtype=float32)\n",
      "array([0.30543205, 0.27106968, 0.39263615, 0.30068994], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_occupation_list = ['arzt','ärztin','krankenschwester','krankenpfleger']\n",
    "print(cosine_similarities_by_words(wv_2020, 'frau', sample_occupation_list))\n",
    "print(cosine_similarities_by_words(wv_2020, 'mann', sample_occupation_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read translated wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TODO</b> write function to load JSON?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('WEAT_german/wissenschaft.json', encoding='utf-8') as data:\n",
    "    wis_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/mathematik.json', encoding='utf-8') as data:\n",
    "    mat_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/kunst.json', encoding='utf-8') as data:\n",
    "    kunst_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/stark.json', encoding='utf-8') as data:\n",
    "    stark_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/schwach.json', encoding='utf-8') as data:\n",
    "    schwach_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/intelligenz.json', encoding='utf-8') as data:\n",
    "    int_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/aussehen.json', encoding='utf-8') as data:\n",
    "    aus_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/beruf.json', encoding='utf-8') as data:\n",
    "    beruf_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/familie.json', encoding='utf-8') as data:\n",
    "    fam_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/weiblich.json', encoding='utf-8') as data:\n",
    "    w_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/maennlich.json', encoding='utf-8') as data:\n",
    "    m_dict = json.load(data)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.we.weat import calc_single_weat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1: career vs. family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'beruf vs. familie',\n",
      " 'd': -1.3503735,\n",
      " 'p': 0.9978243978243978,\n",
      " 's': -0.5250897109508514}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'beruf vs. familie',\n",
      " 'd': -1.3187135,\n",
      " 'p': 0.9965811965811966,\n",
      " 's': -0.5579641908407211}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'beruf vs. familie',\n",
      " 'd': -1.3172334,\n",
      " 'p': 0.9975135975135975,\n",
      " 's': -0.5422469526529312}\n"
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=beruf_dict, \n",
    "                    second_target=fam_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=beruf_dict,  \n",
    "                    second_target=fam_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=beruf_dict, \n",
    "                    second_target=fam_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B2: maths vs. arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'mathematik vs. kunst',\n",
      " 'd': 1.1648192,\n",
      " 'p': 0.00909090909090909,\n",
      " 's': 0.2651319205760956}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'mathematik vs. kunst',\n",
      " 'd': 0.8342018,\n",
      " 'p': 0.054234654234654234,\n",
      " 's': 0.19725701212882996}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'mathematik vs. kunst',\n",
      " 'd': 0.3978146,\n",
      " 'p': 0.2376068376068376,\n",
      " 's': 0.08596093952655792}\n"
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=mat_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=mat_dict,  \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=mat_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B3: science vs arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'wissenschaft vs. kunst',\n",
      " 'd': 0.09958489,\n",
      " 'p': 0.4271950271950272,\n",
      " 's': 0.021453166555147618}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'wissenschaft vs. kunst',\n",
      " 'd': -0.15480079,\n",
      " 'p': 0.6131313131313131,\n",
      " 's': -0.03475114703178406}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'wissenschaft vs. kunst',\n",
      " 'd': -0.70312375,\n",
      " 'p': 0.9051282051282051,\n",
      " 's': -0.21315891668200493}\n"
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=wis_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=wis_dict,  \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=wis_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B4: intelligence vs. appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '11x2',\n",
      " 'Target words': 'intelligenz vs. aussehen',\n",
      " 'd': -0.4827857,\n",
      " 'p': 0.8583959899749374,\n",
      " 's': -0.13892878592014313}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '11x2',\n",
      " 'Target words': 'intelligenz vs. aussehen',\n",
      " 'd': -0.26572827,\n",
      " 'p': 0.7227117567674843,\n",
      " 's': -0.06973184645175934}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '11x2',\n",
      " 'Target words': 'intelligenz vs. aussehen',\n",
      " 'd': 0.07158573,\n",
      " 'p': 0.43606612685560053,\n",
      " 's': 0.021325059235095978}\n"
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=int_dict, \n",
    "                    second_target=aus_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=int_dict,  \n",
    "                    second_target=aus_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=int_dict, \n",
    "                    second_target=aus_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B5: strength vs. weakness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '11x2',\n",
      " 'Target words': 'stark vs. schwach',\n",
      " 'd': -0.31690106,\n",
      " 'p': 0.7578916181857358,\n",
      " 's': -0.08451436460018158}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '11x2',\n",
      " 'Target words': 'stark vs. schwach',\n",
      " 'd': -0.5758694,\n",
      " 'p': 0.9019593667426484,\n",
      " 's': -0.16809803247451782}\n",
      "{'Attrib. words': 'weiblich vs. männlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '11x2',\n",
      " 'Target words': 'stark vs. schwach',\n",
      " 'd': -0.6690417,\n",
      " 'p': 0.936414849340546,\n",
      " 's': -0.17794756591320038}\n"
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=stark_dict, \n",
    "                    second_target=schwach_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=stark_dict,  \n",
    "                    second_target=schwach_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=stark_dict, \n",
    "                    second_target=schwach_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ? Gonen & Goldberg\n",
    "plot_most_biased_clustering(biased, debiased, seed='ends', n_extreme=500, random_state=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1e59edebc369ad65c119260e2f960d0c0cce7d7d487e1def8281e3e9d8bc7df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
