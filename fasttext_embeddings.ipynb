{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train FastText embeddings using gensim</b> (Source: https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus & Preprocess raw text (Remove punctuation and numbers) (ca. 1.5h per corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "new_corpus = []\n",
    "#i=1\n",
    "with open('raw_data/deu_news_2020_1M-sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        doc = nlp(line)\n",
    "        new_line = [token.lower_ for token in doc if token.is_alpha]\n",
    "        for j in range(10):\n",
    "            new_line.append('$')\n",
    "        new_corpus.append(' '.join(new_line))\n",
    "        #i+=1\n",
    "        #if i>200:\n",
    "            #break \n",
    "    f.close()\n",
    "\n",
    "with open('clean_data/deu_news_2020_clean.txt', 'w', encoding='utf-8') as f_out:\n",
    "    for line in new_corpus:\n",
    "        f_out.write(line)\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model (window=5 10 min., 3 -> 6 min., 10 -> 12 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1995 = FastText(sg=1, vector_size=300, window=10)\n",
    "corpus_file_1995 = 'clean_data/deu_news_1995_clean.txt'\n",
    "\n",
    "# build the vocabulary\n",
    "model_1995.build_vocab(corpus_file=corpus_file_1995)\n",
    "\n",
    "# train the model\n",
    "model_1995.train(\n",
    "    corpus_file=corpus_file_1995, epochs=model_1995.epochs,\n",
    "    total_examples=model_1995.corpus_count, total_words=model_1995.corpus_total_words,\n",
    ")\n",
    "\n",
    "print(model_1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vector lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = model_1995.wv\n",
    "print(wv_1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load other corpus & build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2010 = 'clean_data/deu_news_2010_clean.txt'\n",
    "model_2010 = FastText(sg=1, vector_size=300)\n",
    "\n",
    "corpus_file_2020 = 'clean_data/deu_news_2020_clean.txt'\n",
    "model_2020 = FastText(sg=1, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabularies\n",
    "model_2010.build_vocab(corpus_file=corpus_file_2010)\n",
    "model_2020.build_vocab(corpus_file=corpus_file_2020)\n",
    "\n",
    "# train models\n",
    "model_2010.train(\n",
    "    corpus_file=corpus_file_2010, epochs=model_2010.epochs,\n",
    "    total_examples=model_2010.corpus_count, total_words=model_2010.corpus_total_words,\n",
    ")\n",
    "model_2020.train(\n",
    "    corpus_file=corpus_file_2020, epochs=model_2020.epochs,\n",
    "    total_examples=model_2020.corpus_count, total_words=model_2020.corpus_total_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_2010 = model_2010.wv\n",
    "wv_2020 = model_2020.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save words & their embeddings (once training is complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wv_1995.save(\"trained_models/model_1995_training_3_wordvectors\")\n",
    "#wv_2010.save(\"trained_models/model_2010_wordvectors\")\n",
    "#wv_2020.save(\"trained_models/model_2020_wordvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models (2-6 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = KeyedVectors.load(\"trained_models/model_1995_training_3_wordvectors\", mmap='r')\n",
    "wv_2010 = KeyedVectors.load(\"trained_models/model_2010_training_3_wordvectors\", mmap='r')\n",
    "wv_2020 = KeyedVectors.load(\"trained_models/model_2020_training_3_wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some semantic similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_1995.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_1995.similarity(\"frau\", \"채rztin\"))\n",
    "print(wv_1995.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_1995.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_1995.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_2010.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_2010.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_2010.similarity(\"frau\", \"채rztin\"))\n",
    "print(wv_2010.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_2010.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_2010.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_2020.similarity(\"mann\", \"arzt\"))\n",
    "print(wv_2020.similarity(\"frau\", \"arzt\"))\n",
    "print(wv_2020.similarity(\"frau\", \"채rztin\"))\n",
    "print(wv_2020.similarity(\"frau\", \"krankenschwester\"))\n",
    "print(wv_2020.similarity(\"mann\", \"krankenschwester\"))\n",
    "print(wv_2020.similarity(\"mann\", \"krankenpfleger\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print words with most similar vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.most_similar(\"arzt\"))\n",
    "print(wv_2010.most_similar(\"arzt\"))\n",
    "print(wv_2020.most_similar(\"arzt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example analogy set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv_1995.most_similar(positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(wv_2010.most_similar(positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(wv_2020.most_similar(positive=['frau', 'arzt'], negative=['mann']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization with PCA (Source: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/) > 12 min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a 2d PCA model to the vectors\n",
    "X = wv_1995\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(wv_1995[:20])\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "display_pca_scatterplot(model, sample=300)\n",
    "\n",
    "# display_pca_scatterplot(model, ['frau', 'mann', 'arzt', '채rztin'])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate general performance on semantic German analogy set, Source: https://devmount.github.io/GermanWordEmbeddings/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_1995.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_2010.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies_result = wv_2020.evaluate_word_analogies('questions/semantic_evaluation.txt')\n",
    "print(analogies_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim English question set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analogies_result = wv_2020.evaluate_word_analogies('questions/gensim questions-words.txt')\n",
    "#print(analogies_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Word Embedding Association Test (WEAT) by Chaloner & Maldonado (2019)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias categories:\n",
    "\n",
    "B1: career vs family\n",
    "B2: maths vs arts \n",
    "B3: science vs arts \n",
    "B4: intelligence vs appearance\n",
    "B5: strength vs weakness\n",
    "\n",
    "Both groups of target words per category are compared to the two attribute sets female and male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models and save word vectors with gensim 4.0.1 (10 min. per model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TODO</b> Retrain with different parameters -> window size !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_1995 = 'clean_data/deu_news_1995_clean.txt'\n",
    "model_1995 = FastText(sg=1, size=300)\n",
    "model_1995.build_vocab(corpus_file=corpus_file_1995)\n",
    "model_1995.train(\n",
    "    corpus_file=corpus_file_1995, epochs=model_1995.epochs,\n",
    "    total_examples=model_1995.corpus_count, total_words=model_1995.corpus_total_words,\n",
    ")\n",
    "wv_1995 = model_1995.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2010 = 'clean_data/deu_news_2010_clean.txt'\n",
    "model_2010 = FastText(sg=1, size=300)\n",
    "model_2010.build_vocab(corpus_file=corpus_file_2010)\n",
    "model_2010.train(\n",
    "    corpus_file=corpus_file_2010, epochs=model_2010.epochs,\n",
    "    total_examples=model_2010.corpus_count, total_words=model_2010.corpus_total_words,\n",
    ")\n",
    "wv_2010 = model_2010.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_2020 = 'clean_data/deu_news_2020_clean.txt'\n",
    "model_2020 = FastText(sg=1, size=300)\n",
    "model_2020.build_vocab(corpus_file=corpus_file_2020)\n",
    "model_2020.train(\n",
    "    corpus_file=corpus_file_2020, epochs=model_2020.epochs,\n",
    "    total_examples=model_2020.corpus_count, total_words=model_2020.corpus_total_words,\n",
    ")\n",
    "wv_2020 = model_2020.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save old version keyed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995.save(\"gensim4.0.1_ft_models/vectors_1995.kv\")\n",
    "wv_2010.save(\"gensim4.0.1_ft_models/vectors_2010.kv\")\n",
    "wv_2020.save(\"gensim4.0.1_ft_models/vectors_2020.kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load old version keyed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1995 = KeyedVectors.load(\"gensim4.0.1_ft_models/vectors_1995.kv\", mmap='r')\n",
    "wv_2010 = KeyedVectors.load(\"gensim4.0.1_ft_models/vectors_2010.kv\", mmap='r')\n",
    "wv_2020 = KeyedVectors.load(\"gensim4.0.1_ft_models/vectors_2020.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration with Responsibly (https://docs.responsibly.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.we.utils import most_similar, cosine_similarities_by_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute most similar words without restriction (words from sets may be repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(most_similar(wv_1995, positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(most_similar(wv_2010, positive=['frau', 'arzt'], negative=['mann']))\n",
    "print(most_similar(wv_2020, positive=['frau', 'arzt'], negative=['mann']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_occupation_list = ['arzt','채rztin','krankenschwester','krankenpfleger']\n",
    "print(cosine_similarities_by_words(wv_2020, 'frau', sample_occupation_list))\n",
    "print(cosine_similarities_by_words(wv_2020, 'mann', sample_occupation_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read translated wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TODO</b> write function to load JSON?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('WEAT_german/wissenschaft.json', encoding='utf-8') as data:\n",
    "    wis_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/mathematik.json', encoding='utf-8') as data:\n",
    "    mat_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/kunst.json', encoding='utf-8') as data:\n",
    "    kunst_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/stark.json', encoding='utf-8') as data:\n",
    "    stark_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/schwach.json', encoding='utf-8') as data:\n",
    "    schwach_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/intelligenz.json', encoding='utf-8') as data:\n",
    "    int_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/aussehen.json', encoding='utf-8') as data:\n",
    "    aus_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/beruf.json', encoding='utf-8') as data:\n",
    "    beruf_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/familie.json', encoding='utf-8') as data:\n",
    "    fam_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/weiblich.json', encoding='utf-8') as data:\n",
    "    w_dict = json.load(data)\n",
    "    data.close()\n",
    "\n",
    "with open('WEAT_german/maennlich.json', encoding='utf-8') as data:\n",
    "    m_dict = json.load(data)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.we.weat import calc_single_weat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1: career vs. family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Attrib. words': 'weiblich vs. m채nnlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'beruf vs. familie',\n",
      " 'd': -1.2226075,\n",
      " 'p': 0.9946386946386946,\n",
      " 's': -0.5006231814622879}\n",
      "{'Attrib. words': 'weiblich vs. m채nnlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'beruf vs. familie',\n",
      " 'd': -1.0798489,\n",
      " 'p': 0.9836829836829837,\n",
      " 's': -0.4299915134906769}\n",
      "{'Attrib. words': 'weiblich vs. m채nnlich',\n",
      " 'Na': '11x2',\n",
      " 'Nt': '8x2',\n",
      " 'Target words': 'beruf vs. familie',\n",
      " 'd': -1.3993838,\n",
      " 'p': 0.9984459984459985,\n",
      " 's': -0.5612092316150665}\n"
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=beruf_dict, \n",
    "                    second_target=fam_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=beruf_dict,  \n",
    "                    second_target=fam_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=beruf_dict, \n",
    "                    second_target=fam_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B2: maths vs. arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=mat_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=mat_dict,  \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=mat_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B3: science vs arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=wis_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=wis_dict,  \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=wis_dict, \n",
    "                    second_target=kunst_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B4: intelligence vs. appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MICHIM~1\\AppData\\Local\\Temp/ipykernel_33156/4251015471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m print(calc_single_weat(model=wv_1995, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mfirst_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0msecond_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maus_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mfirst_attribute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     second_attribute=m_dict))\n",
      "\u001b[1;32m~\\Documents\\Environments\\test\\lib\\site-packages\\responsibly\\we\\weat.py\u001b[0m in \u001b[0;36mcalc_single_weat\u001b[1;34m(model, first_target, second_target, first_attribute, second_attribute, with_pvalue, pvalue_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mpvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_pvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             pvalue = _calc_weat_pvalue(first_associations,\n\u001b[0m\u001b[0;32m    267\u001b[0m                                        \u001b[0msecond_associations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                                        **pvalue_kwargs)\n",
      "\u001b[1;32m~\\Documents\\Environments\\test\\lib\\site-packages\\responsibly\\we\\weat.py\u001b[0m in \u001b[0;36m_calc_weat_pvalue\u001b[1;34m(first_associations, second_associations, method)\u001b[0m\n\u001b[0;32m    135\u001b[0m             PVALUE_METHODS, method))\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     pvalue = permutation_test(first_associations, second_associations,\n\u001b[0m\u001b[0;32m    138\u001b[0m                               \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Environments\\test\\lib\\site-packages\\mlxtend\\evaluate\\permutation.py\u001b[0m in \u001b[0;36mpermutation_test\u001b[1;34m(x, y, func, method, num_rounds, seed)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mindices_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mreference_stat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=int_dict, \n",
    "                    second_target=aus_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "\"\"\"print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=int_dict,  \n",
    "                    second_target=aus_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=int_dict, \n",
    "                    second_target=aus_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B5: strength vs. weakness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_single_weat(model=wv_1995, \n",
    "                    first_target=stark_dict, \n",
    "                    second_target=schwach_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2010, \n",
    "                    first_target=stark_dict,  \n",
    "                    second_target=schwach_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))\n",
    "\n",
    "print(calc_single_weat(model=wv_2020, \n",
    "                    first_target=stark_dict, \n",
    "                    second_target=schwach_dict, \n",
    "                    first_attribute=w_dict, \n",
    "                    second_attribute=m_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ? Gonen & Goldberg\n",
    "plot_most_biased_clustering(biased, debiased, seed='ends', n_extreme=500, random_state=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1e59edebc369ad65c119260e2f960d0c0cce7d7d487e1def8281e3e9d8bc7df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
